{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51a423c-145e-4a6c-9bd1-0a8b0ae9fa8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install langchain langchain_community langchain_chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d421301a-cfe6-48e8-b8ef-9e85a446ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958b80db",
   "metadata": {},
   "source": [
    "## Methods to Setup Environmental Variables for API Access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75702032",
   "metadata": {},
   "source": [
    "### Method 1: Enter Manually on Run (More Secure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75da1cea-67b6-4427-b83a-cb3543cd06de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2eda1ae0-c0d9-4f31-8374-76eecb95548c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_API_KEY'] = getpass.getpass('LANGCHAIN_API_KEY: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e40e76a",
   "metadata": {},
   "source": [
    "### Method 2: Setup .env file with API keys and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f050dc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77215a4e-c01f-44a6-90de-72b2d59638dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a7818fd-838f-4553-a043-74b3a7662c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://llamaimodel.com/requirements/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=('stats-table')\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5d4c6e3-622c-4fc6-bf18-25a281d2281a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "152a6851-9e51-4b98-bcf9-479801aae79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9aace7f1-f617-4b8c-96a3-23e3c8c485a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OllamaEmbeddings(\n",
    "    model='llama3.1'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45187264-9e00-4109-af79-4241de9e35d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bab18e94-d78f-47c1-9783-d4e53fa90403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorstore.delete_collection()\n",
    "# vectorstore.reset_collection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3883c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "917db71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model='llama3.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a38f1129-2fe4-44f6-9fae-8cca9e7f7fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retriever = vectorstore.as_retriever()\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c0d9854-1646-40d3-ba24-92f7397beb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The article is about the specifications and requirements for different models of Llama 3.1, including hardware and software dependencies. The models include 8B, 70B, and 405B, with varying parameters, context length, and multilingual support. It lists detailed hardware and software requirements for each model.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"What's the article about?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9119651-1a1c-47be-a6b4-3c89f21e1297",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here are the requirements for the 8b model:\\n\\nThe 8b model requires a modern processor with at least 8 cores and 16 GB of RAM, as well as an NVIDIA RTX 3090 (24 GB) or RTX 4090 (24 GB) GPU in 16-bit mode. The estimated GPU memory requirements are approximately 19.2 GB in 16-bit mode, 9.6 GB in 8-bit mode, and 4.8 GB in 4-bit mode.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"List the requirements for the 8b model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d2c62-54d5-4e71-881c-cb6218f8f0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
